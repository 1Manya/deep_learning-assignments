{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UnPQIOfC9ZVm"
      },
      "outputs": [],
      "source": [
        "# step function\n",
        "def step_function(value):\n",
        "  if value >= 0:\n",
        "    return 1\n",
        "  else :\n",
        "    return 0\n",
        "\n",
        "# prediction function\n",
        "def predict(x,weights,bias):\n",
        "  weighted_sum = 0\n",
        "  for i in range(len(x)):\n",
        "    weighted_sum +=x[i]*weights[i]\n",
        "  weighted_sum += bias\n",
        "  return step_function(weighted_sum)\n",
        "\n",
        "# training function\n",
        "def train_perceptron(inputs,targets,learning_rate,epochs):\n",
        "  # initialize weights and bias\n",
        "  weights = [0,0]\n",
        "  bias = 0\n",
        "  for epoch in range(epochs):\n",
        "    for i in range(len(inputs)):\n",
        "      x=inputs[i]\n",
        "      y_true = targets[i]\n",
        "      y_pred = predict(x,weights,bias)\n",
        "      error = y_true - y_pred\n",
        "\n",
        "      #update weights\n",
        "      for j in range(len(weights)):\n",
        "        weights[j]=weights[j] +learning_rate*error*x[j]\n",
        "\n",
        "      # update bias\n",
        "      bias = bias + learning_rate*error\n",
        "  return weights,bias\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input data\n",
        "inputs = [\n",
        "    [0,0],\n",
        "    [0,1],\n",
        "    [1,0],\n",
        "    [1,1]\n",
        "    ]"
      ],
      "metadata": {
        "id": "fNCjdHDCFEKh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AND gate"
      ],
      "metadata": {
        "id": "XhRELB88HAlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "and_t = [0,0,0,1]\n",
        "weights,bias = train_perceptron(inputs,and_t,0.1,20)\n",
        "\n",
        "print(\"AND gate\")\n",
        "print(\"weights:\",weights)\n",
        "print(\"bias:\",bias)\n",
        "\n",
        "for x in inputs:\n",
        "  print(x,\"-->\",predict(x,weights,bias))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix9eQdsTFQRI",
        "outputId": "703dba40-d8bb-454e-c7de-cd248264bbec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND gate\n",
            "weights: [0.2, 0.1]\n",
            "bias: -0.20000000000000004\n",
            "[0, 0] --> 0\n",
            "[0, 1] --> 0\n",
            "[1, 0] --> 0\n",
            "[1, 1] --> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OR gate"
      ],
      "metadata": {
        "id": "tHJiE8KqHD9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "or_t = [0,1,1,1]\n",
        "weights,bias = train_perceptron(inputs ,or_t,0.1,20)\n",
        "print(\"OR gate \")\n",
        "print(\"weights:\",weights)\n",
        "print(\"bias:\",bias)\n",
        "for x in inputs:\n",
        "  print(x,\"-->\",predict(x,weights,bias))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piIZIa5tHGfZ",
        "outputId": "89978af9-6ba8-4c90-c9f4-e57fe63cefa6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR gate \n",
            "weights: [0.1, 0.1]\n",
            "bias: -0.1\n",
            "[0, 0] --> 0\n",
            "[0, 1] --> 1\n",
            "[1, 0] --> 1\n",
            "[1, 1] --> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NAND gate"
      ],
      "metadata": {
        "id": "6sTO7NF1H5Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nand_t=[1,1,1,0]\n",
        "weights,bias = train_perceptron(inputs,nand_t,0.1,20)\n",
        "print(\"NAND gate\")\n",
        "print(\"weights:\",weights)\n",
        "print(\"bias:\",bias)\n",
        "for x in inputs:\n",
        "  print(x,\"-->\",predict(x,weights,bias))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sjVRz6ZH4xW",
        "outputId": "6489707c-2933-4b8e-827d-6af9a1855c8e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAND gate\n",
            "weights: [-0.2, -0.1]\n",
            "bias: 0.2\n",
            "[0, 0] --> 1\n",
            "[0, 1] --> 1\n",
            "[1, 0] --> 1\n",
            "[1, 1] --> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOR gate"
      ],
      "metadata": {
        "id": "NAqlvpWpI00S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nor_t = [1, 0, 0, 0]\n",
        "\n",
        "weights, bias = train_perceptron(inputs, nor_t, 0.1, 20)\n",
        "\n",
        "print(\"\\nNOR Gate\")\n",
        "print(\"Weights:\", weights)\n",
        "print(\"Bias:\", bias)\n",
        "\n",
        "for x in inputs:\n",
        "    print(x, \"->\", predict(x, weights, bias))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JjztHRpIrDH",
        "outputId": "c73b8872-d7bc-4863-a430-968dc462df21"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NOR Gate\n",
            "Weights: [-0.1, -0.1]\n",
            "Bias: 0.0\n",
            "[0, 0] -> 1\n",
            "[0, 1] -> 0\n",
            "[1, 0] -> 0\n",
            "[1, 1] -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XOR gate"
      ],
      "metadata": {
        "id": "Px6pehWtI3rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xor_t= [0,1,1,0]\n",
        "weights, bias = train_perceptron(inputs,xor_t,0.1,20)\n",
        "print(\"XOR gate \")\n",
        "print(\"weights:\",weights)\n",
        "print(\"bias\",bias)\n",
        "for x in inputs:\n",
        "  print(x,\"-->\",predict(x,weights,bias))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geEzgmXrIynx",
        "outputId": "50dd7687-9d7c-441d-eed8-39f98bad54d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR gate \n",
            "weights: [-0.1, 0.0]\n",
            "bias 0.0\n",
            "[0, 0] --> 1\n",
            "[0, 1] --> 1\n",
            "[1, 0] --> 0\n",
            "[1, 1] --> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " xor is not linearly separable\n",
        " --> it need two lines\n",
        " --> single layer perceptron cannot learn XOR --> this limitation led to multilayer neural networks\n",
        "\n"
      ],
      "metadata": {
        "id": "kVc-oQ4MS9jS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## effect of learning rate\n",
        "if learning rate is     \n",
        "\n",
        "*  too small-->very slow learning\n",
        "\n",
        "*  too large-->unstable ,may not converge\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M3vRixJKW7-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why the Same Code Learned Different Logic Gates?\n",
        "\n",
        "The same perceptron code learned different logic gates because the target outputs were different for each gate.\n",
        "During training, different target values produce different errors, which leads to different weight and bias updates.\n",
        "As a result, the perceptron learns different decision boundaries for different logic gates."
      ],
      "metadata": {
        "id": "GsJqiUuKYPNM"
      }
    }
  ]
}